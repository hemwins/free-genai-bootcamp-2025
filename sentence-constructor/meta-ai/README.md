### MetaAI Powered assitant guide

## Model detail

https://huggingface.co/meta-llama/Meta-Llama-3-70B

- I'm based on Llama 3, a large language model developed by Meta. I have approximately 70 billion parameters.

- I'm a single model, which means I'm a unified neural network architecture that processes and responds to natural language inputs.

- I'm a closed-weight model, meaning my weights and training data are not publicly accessible. However, my underlying architecture and training objectives are based on the open-source LLaMA model developed by Meta AI.

## Prompting guide

https://www.llama.com/docs/how-to-guides/prompting/

There are 4 different roles that are supported by Llama text models:

-system: Sets the context in which to interact with the AI model. It typically includes rules, guidelines, or necessary information that help the model respond effectively.
-user: Represents the human interacting with the model. It includes the inputs, commands, and questions to the model.
-ipython: A new role introduced in Llama 3.1. Semantically, this role means "tool". This role is used to mark messages with the output of a tool call when sent back to the model from the executor. (WE DID NOT USE THIS EXPLICITLY IN OUR PROMPTS)
-assistant: Represents the response generated by the AI model based on the context provided in the system, ipython and user prompts.

## Techniques

-First three prompts used zero shot prompting technique
-Fourth prompt used few shot prompting technique, as it provided the expected answer output example in context.